{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from official.projects.movinet.modeling import movinet\n",
    "from official.projects.movinet.modeling import movinet_model\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "from math import floor\n",
    "from typing import Iterable, Optional\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.utils import (Sequence, img_to_array)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T08:41:36.505229Z",
     "iopub.status.busy": "2023-03-22T08:41:36.504869Z",
     "iopub.status.idle": "2023-03-22T08:41:45.474557Z",
     "shell.execute_reply": "2023-03-22T08:41:45.465860Z",
     "shell.execute_reply.started": "2023-03-22T08:41:36.505194Z"
    },
    "id": "yTLZzkd-lFTF"
   },
   "outputs": [],
   "source": [
    "def setup():\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    class VideoFrameGenerator(Sequence):  # pylint: disable=too-many-instance-attributes\n",
    "        \"\"\"\n",
    "        Create a generator that return batches of frames from video\n",
    "        - rescale: float fraction to rescale pixel data (commonly 1/255.)\n",
    "        - nb_frames: int, number of frames to return for each sequence\n",
    "        - classes: list of str, classes to infer\n",
    "        - batch_size: int, batch size for each loop\n",
    "        - use_frame_cache: bool, use frame cache (may take a lot of memory for \\\n",
    "            large dataset)\n",
    "        - shape: tuple, target size of the frames\n",
    "        - shuffle: bool, randomize files\n",
    "        - transformation: ImageDataGenerator with transformations\n",
    "        - split: float, factor to split files and validation\n",
    "        - nb_channel: int, 1 or 3, to get grayscaled or RGB images\n",
    "        - glob_pattern: string, directory path with '{classname}' inside that \\\n",
    "            will be replaced by one of the class list\n",
    "        - use_header: bool, default to True to use video header to read the \\\n",
    "            frame count if possible\n",
    "        - seed: int, default to None, keep the seed value for split\n",
    "        You may use the \"classes\" property to retrieve the class list afterward.\n",
    "        The generator has that properties initialized:\n",
    "        - classes_count: number of classes that the generator manages\n",
    "        - files_count: number of video that the generator can provides\n",
    "        - classes: the given class list\n",
    "        - files: the full file list that the generator will use, this \\\n",
    "            is usefull if you want to remove some files that should not be \\\n",
    "            used by the generator.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(  # pylint: disable=too-many-statements,too-many-locals,too-many-branches,too-many-arguments\n",
    "            self,\n",
    "            rescale: float = 1 / 255.0,\n",
    "            nb_frames: int = 5,\n",
    "            classes: list = None,\n",
    "            batch_size: int = 16,\n",
    "            use_frame_cache: bool = False,\n",
    "            target_shape: tuple = (224, 224),\n",
    "            shuffle: bool = True,\n",
    "            transformation: Optional[ImageDataGenerator] = None,\n",
    "            split_test: float = None,\n",
    "            split_val: float = None,\n",
    "            nb_channel: int = 3,\n",
    "            glob_pattern: str = \"./videos/{classname}/*.avi\",\n",
    "            use_headers: bool = True,\n",
    "            seed=None,\n",
    "            **kwargs,\n",
    "        ):\n",
    "\n",
    "            self.glob_pattern = glob_pattern\n",
    "\n",
    "            # should be only RGB or Grayscale\n",
    "            assert nb_channel in (1, 3)\n",
    "\n",
    "            if classes is None:\n",
    "                classes = self._discover_classes()\n",
    "\n",
    "            # we should have classes\n",
    "            if len(classes) == 0:\n",
    "                log.warn(\n",
    "                    \"You didn't provide classes list or \"\n",
    "                    \"we were not able to discover them from \"\n",
    "                    \"your pattern.\\n\"\n",
    "                    \"Please check if the path is OK, and if the glob \"\n",
    "                    \"pattern is correct.\\n\"\n",
    "                    \"See https://docs.python.org/3/library/glob.html\"\n",
    "                )\n",
    "\n",
    "            # shape size should be 2\n",
    "            assert len(target_shape) == 2\n",
    "\n",
    "            # split factor should be a propoer value\n",
    "            if split_val is not None:\n",
    "                assert 0.0 < split_val < 1.0\n",
    "\n",
    "            if split_test is not None:\n",
    "                assert 0.0 < split_test < 1.0\n",
    "\n",
    "            self.use_video_header = use_headers\n",
    "\n",
    "            # then we don't need None anymore\n",
    "            split_val = split_val if split_val is not None else 0.0\n",
    "            split_test = split_test if split_test is not None else 0.0\n",
    "\n",
    "            # be sure that classes are well ordered\n",
    "            classes.sort()\n",
    "\n",
    "            self.rescale = rescale\n",
    "            self.classes = classes\n",
    "            self.batch_size = batch_size\n",
    "            self.nbframe = nb_frames\n",
    "            self.shuffle = shuffle\n",
    "            self.target_shape = target_shape\n",
    "            self.nb_channel = nb_channel\n",
    "            self.transformation = transformation\n",
    "            self.use_frame_cache = use_frame_cache\n",
    "\n",
    "            self._random_trans = []\n",
    "            self.__frame_cache = {}\n",
    "            self.files = []\n",
    "            self.validation = []\n",
    "            self.test = []\n",
    "\n",
    "            _validation_data = kwargs.get(\"_validation_data\", None)\n",
    "            _test_data = kwargs.get(\"_test_data\", None)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            if _validation_data is not None:\n",
    "                # we only need to set files here\n",
    "                self.files = _validation_data\n",
    "\n",
    "            elif _test_data is not None:\n",
    "                # we only need to set files here\n",
    "                self.files = _test_data\n",
    "            else:\n",
    "                self.__split_from_vals(\n",
    "                    split_val, split_test, classes, shuffle, glob_pattern\n",
    "                )\n",
    "\n",
    "            # build indexes\n",
    "            self.files_count = len(self.files)\n",
    "            self.indexes = np.arange(self.files_count)\n",
    "            self.classes_count = len(classes)\n",
    "\n",
    "            # to initialize transformations and shuffle indices\n",
    "            if \"no_epoch_at_init\" not in kwargs:\n",
    "                self.on_epoch_end()\n",
    "\n",
    "            kind = \"train\"\n",
    "            if _validation_data is not None:\n",
    "                kind = \"validation\"\n",
    "            elif _test_data is not None:\n",
    "                kind = \"test\"\n",
    "\n",
    "            self._current = 0\n",
    "            self._framecounters = {}\n",
    "\n",
    "        def count_frames(self, cap, name, force_no_headers=False):\n",
    "            \"\"\"Count number of frame for video\n",
    "            if it's not possible with headers\"\"\"\n",
    "            if not force_no_headers and name in self._framecounters:\n",
    "                return self._framecounters[name]\n",
    "\n",
    "            total = cap.get(cv.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "            if force_no_headers or total < 0:\n",
    "                # headers not ok\n",
    "                total = 0\n",
    "                # TODO: we're unable to use CAP_PROP_POS_FRAME here\n",
    "                # so we open a new capture to not change the\n",
    "                # pointer position of \"cap\"\n",
    "                capture = cv.VideoCapture(name)\n",
    "                while True:\n",
    "                    grabbed, _ = capture.read()\n",
    "                    if not grabbed:\n",
    "                        # rewind and stop\n",
    "                        break\n",
    "                    total += 1\n",
    "\n",
    "            # keep the result\n",
    "            self._framecounters[name] = total\n",
    "\n",
    "            return total\n",
    "\n",
    "        def __split_from_vals(self, split_val, split_test, classes, shuffle, glob_pattern):\n",
    "            \"\"\" Split validation and test set \"\"\"\n",
    "\n",
    "            if split_val == 0 or split_test == 0:\n",
    "                # no splitting, do the simplest thing\n",
    "                for cls in classes:\n",
    "                    self.files += glob.glob(glob_pattern.format(classname=cls))\n",
    "                return\n",
    "\n",
    "            # else, there is some split to do\n",
    "            for cls in classes:\n",
    "                files = glob.glob(glob_pattern.format(classname=cls))\n",
    "                nbval = 0\n",
    "                nbtest = 0\n",
    "                info = []\n",
    "\n",
    "                # generate validation and test indexes\n",
    "                indexes = np.arange(len(files))\n",
    "\n",
    "                if shuffle:\n",
    "                    np.random.shuffle(indexes)\n",
    "\n",
    "                nbtrain = 0\n",
    "                if 0.0 < split_val < 1.0:\n",
    "                    nbval = int(split_val * len(files))\n",
    "                    nbtrain = len(files) - nbval\n",
    "\n",
    "                    # get some sample for validation_data\n",
    "                    val = np.random.permutation(indexes)[:nbval]\n",
    "\n",
    "                    # remove validation from train\n",
    "                    indexes = np.array([i for i in indexes if i not in val])\n",
    "                    self.validation += [files[i] for i in val]\n",
    "                    info.append(\"validation count: %d\" % nbval)\n",
    "\n",
    "                if 0.0 < split_test < 1.0:\n",
    "                    nbtest = int(split_test * nbtrain)\n",
    "                    nbtrain = len(files) - nbval - nbtest\n",
    "\n",
    "                    # get some sample for test_data\n",
    "                    val_test = np.random.permutation(indexes)[:nbtest]\n",
    "\n",
    "                    # remove test from train\n",
    "                    indexes = np.array([i for i in indexes if i not in val_test])\n",
    "                    self.test += [files[i] for i in val_test]\n",
    "                    info.append(\"test count: %d\" % nbtest)\n",
    "\n",
    "                # and now, make the file list\n",
    "                self.files += [files[i] for i in indexes]\n",
    "                print(\"class %s, %s, train count: %d\" % (cls, \", \".join(info), nbtrain))\n",
    "\n",
    "        def _discover_classes(self):\n",
    "            pattern = os.path.realpath(self.glob_pattern)\n",
    "            pattern = re.escape(pattern)\n",
    "            pattern = pattern.replace(\"\\\\{classname\\\\}\", \"(.*?)\")\n",
    "            pattern = pattern.replace(\"\\\\*\", \".*\")\n",
    "\n",
    "            files = glob.glob(self.glob_pattern.replace(\"{classname}\", \"*\"))\n",
    "            classes = set()\n",
    "            for filename in files:\n",
    "                filename = os.path.realpath(filename)\n",
    "                classname = re.findall(pattern, filename)[0]\n",
    "                classes.add(classname)\n",
    "\n",
    "            return list(classes)\n",
    "\n",
    "        def next(self):\n",
    "            \"\"\" Return next element\"\"\"\n",
    "            elem = self[self._current]\n",
    "            self._current += 1\n",
    "            if self._current == len(self):\n",
    "                self._current = 0\n",
    "                self.on_epoch_end()\n",
    "\n",
    "            return elem\n",
    "\n",
    "        def get_validation_generator(self):\n",
    "            \"\"\" Return the validation generator if you've provided split factor \"\"\"\n",
    "            return self.__class__(\n",
    "                nb_frames=self.nbframe,\n",
    "                nb_channel=self.nb_channel,\n",
    "                target_shape=self.target_shape,\n",
    "                classes=self.classes,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=self.shuffle,\n",
    "                rescale=self.rescale,\n",
    "                glob_pattern=self.glob_pattern,\n",
    "                use_headers=self.use_video_header,\n",
    "                _validation_data=self.validation,\n",
    "            )\n",
    "\n",
    "        def get_test_generator(self):\n",
    "            \"\"\" Return the validation generator if you've provided split factor \"\"\"\n",
    "            return self.__class__(\n",
    "                nb_frames=self.nbframe,\n",
    "                nb_channel=self.nb_channel,\n",
    "                target_shape=self.target_shape,\n",
    "                classes=self.classes,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=self.shuffle,\n",
    "                rescale=self.rescale,\n",
    "                glob_pattern=self.glob_pattern,\n",
    "                use_headers=self.use_video_header,\n",
    "                _test_data=self.test,\n",
    "            )\n",
    "\n",
    "        def on_epoch_end(self):\n",
    "            \"\"\" Called by Keras after each epoch \"\"\"\n",
    "\n",
    "            if self.transformation is not None:\n",
    "                self._random_trans = []\n",
    "                for _ in range(self.files_count):\n",
    "                    self._random_trans.append(\n",
    "                        self.transformation.get_random_transform(self.target_shape)\n",
    "                    )\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.indexes)\n",
    "\n",
    "        def __iter__(self):\n",
    "            return self\n",
    "\n",
    "        def __next__(self):\n",
    "            return self.next()\n",
    "\n",
    "        def __len__(self):\n",
    "            return int(np.floor(self.files_count / self.batch_size))\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            classes = self.classes\n",
    "            shape = self.target_shape\n",
    "            nbframe = self.nbframe\n",
    "\n",
    "            labels = []\n",
    "            images = []\n",
    "\n",
    "            indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "\n",
    "            transformation = None\n",
    "\n",
    "            for i in indexes:\n",
    "\n",
    "                video = self.files[i]\n",
    "                classname = self._get_classname(video)\n",
    "\n",
    "                # create a label array and set 1 to the right column\n",
    "                label = np.zeros(len(classes))\n",
    "                col = classes.index(classname)\n",
    "                label[col] = 1.0\n",
    "\n",
    "                if video not in self.__frame_cache:\n",
    "                    frames = self._get_frames(\n",
    "                        video, nbframe, shape, force_no_headers=not self.use_video_header\n",
    "                    )\n",
    "                    if frames is None:\n",
    "                        # avoid failure, nevermind that video...\n",
    "                        continue\n",
    "\n",
    "                    # add to cache\n",
    "                    if self.use_frame_cache:\n",
    "                        self.__frame_cache[video] = frames\n",
    "\n",
    "                else:\n",
    "                    frames = self.__frame_cache[video]\n",
    "\n",
    "                # apply transformation\n",
    "                # if provided\n",
    "                if self.transformation is not None:\n",
    "                    transformation = self._random_trans[i]\n",
    "                    frames = [\n",
    "    #                     custom_function(self.transformation.apply_transform(frame, transformation))\n",
    "                        self.transformation.apply_transform(frame, transformation)\n",
    "                        if transformation is not None\n",
    "                        else frame\n",
    "                        for frame in frames\n",
    "                    ]\n",
    "\n",
    "                # add the sequence in batch\n",
    "                images.append(frames)\n",
    "                labels.append(label)\n",
    "\n",
    "            return np.array(images), np.array(labels)\n",
    "\n",
    "        def _get_classname(self, video: str) -> str:\n",
    "            \"\"\" Find classname from video filename following the pattern \"\"\"\n",
    "\n",
    "            # work with real path\n",
    "            video = os.path.realpath(video)\n",
    "            pattern = os.path.realpath(self.glob_pattern)\n",
    "\n",
    "            # remove special regexp chars\n",
    "            pattern = re.escape(pattern)\n",
    "\n",
    "            # get back \"*\" to make it \".*\" in regexp\n",
    "            pattern = pattern.replace(\"\\\\*\", \".*\")\n",
    "\n",
    "            # use {classname} as a capture\n",
    "            pattern = pattern.replace(\"\\\\{classname\\\\}\", \"(.*?)\")\n",
    "\n",
    "            # and find all occurence\n",
    "            classname = re.findall(pattern, video)[0]\n",
    "            return classname\n",
    "\n",
    "        def _get_frames(\n",
    "            self, video, nbframe, shape, force_no_headers=False\n",
    "        ) -> Optional[Iterable]:\n",
    "            cap = cv.VideoCapture(video)\n",
    "            total_frames = self.count_frames(cap, video, force_no_headers)\n",
    "            orig_total = total_frames\n",
    "\n",
    "            if total_frames % 2 != 0:\n",
    "                total_frames += 1\n",
    "\n",
    "            frame_step = floor(total_frames / (nbframe - 1))\n",
    "            # TODO: fix that, a tiny video can have a frame_step that is\n",
    "            # under 1\n",
    "            frame_step = max(1, frame_step)\n",
    "            frames = []\n",
    "            frame_i = 0\n",
    "\n",
    "            while True:\n",
    "                grabbed, frame = cap.read()\n",
    "                if not grabbed:\n",
    "                    break\n",
    "\n",
    "                self.__add_and_convert_frame(\n",
    "                    frame, frame_i, frames, orig_total, shape, frame_step\n",
    "                )\n",
    "\n",
    "                if len(frames) == nbframe:\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "\n",
    "            if not force_no_headers and len(frames) != nbframe:\n",
    "                # There is a problem here\n",
    "                # That means that frame count in header is wrong or broken,\n",
    "                # so we need to force the full read of video to get the right\n",
    "                # frame counter\n",
    "                return self._get_frames(video, nbframe, shape, force_no_headers=True)\n",
    "\n",
    "            if force_no_headers and len(frames) != nbframe:\n",
    "                # and if we really couldn't find the real frame counter\n",
    "                # so we return None. Sorry, nothing can be done...\n",
    "                log.error(\n",
    "                    f\"Frame count is not OK for video {video}, \"\n",
    "                    f\"{total_frames} total, {len(frames)} extracted\"\n",
    "                )\n",
    "                return None\n",
    "\n",
    "            return np.array(frames)\n",
    "\n",
    "        def __add_and_convert_frame(  # pylint: disable=too-many-arguments\n",
    "            self, frame, frame_i, frames, orig_total, shape, frame_step\n",
    "        ):\n",
    "            frame_i += 1\n",
    "            if frame_i in (1, orig_total) or frame_i % frame_step == 0:\n",
    "                # resize\n",
    "                frame = cv.resize(frame, shape)\n",
    "\n",
    "                # use RGB or Grayscale ?\n",
    "                frame = (\n",
    "                    cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "                    if self.nb_channel == 3\n",
    "                    else cv.cvtColor(frame, cv.COLOR_RGB2GRAY)\n",
    "                )\n",
    "\n",
    "                # to np\n",
    "                frame = img_to_array(frame) * self.rescale\n",
    "\n",
    "                # keep frame\n",
    "                frames.append(frame)\n",
    "    model_id = 'a2'\n",
    "    resolution = 224\n",
    "    batch_size=8\n",
    "    num_frames=10\n",
    "    tf.keras.backend.clear_session()\n",
    "    use_positional_encoding = model_id in {'a3','a4','a5'}\n",
    "\n",
    "    backbone = movinet.Movinet(model_id=model_id, conv_type ='2plus1d', se_type='2plus3d', activation='hard_swish', gating_activation='hard_sigmoid', use_positional_encoding=use_positional_encoding )\n",
    "    backbone.trainable = True\n",
    "\n",
    "    model = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600)\n",
    "    model.build([None, None, None, None, 3])\n",
    "\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "            filepath='/content/drive/MyDrive/cp.ckpt3',\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "\n",
    "        )\n",
    "\n",
    "    def build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n",
    "        model = movinet_model.MovinetClassifier(\n",
    "        backbone=backbone,\n",
    "        num_classes=num_classes)\n",
    "        model.build([batch_size, num_frames, resolution, resolution, 3])\n",
    "\n",
    "        return model\n",
    "\n",
    "    model = build_classifier(batch_size, num_frames, resolution, backbone, 8)\n",
    "\n",
    "    num_epochs = 30\n",
    "\n",
    "    loss_obj = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    optimizer = tfa.optimizers.AdaBelief(learning_rate = 0.0007, weight_decay= 0.0001)\n",
    "    print(model.summary())\n",
    "    model.compile(loss=loss_obj, optimizer=optimizer, metrics=['accuracy'])\n",
    "    model.load_weights(r'C:\\Users\\Asus\\OneDrive\\CommonBrain\\cp.ckpt1')\n",
    "    real_test_gen = VideoFrameGenerator(batch_size=1, nb_frames=10, glob_pattern=r'C:\\Users\\Asus\\Desktop\\3mdad video3 - Copy\\Test 10\\{classname}\\*', shuffle=False)\n",
    "    preds=model.predict(real_test_gen)\n",
    "    prediction_p = tf.nn.softmax(preds)\n",
    "    yhat = np.argmax(prediction_p,axis=1)\n",
    "    return yhat, real_test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(g, yhat, index=0, random=False, row_width=22, row_height=5):\n",
    "    import random as rnd\n",
    "    import secrets\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    options=['Safe Driving','Hair and Makeup', 'Infotainment System','Texting Left','Texting Right','Call left','Call Right','Drowsy']\n",
    "\n",
    "    # Choose a random batch if random=True\n",
    "    if random:\n",
    "        index = secrets.randbelow(len(g))\n",
    "    assert index < len(g)\n",
    "\n",
    "    # Get batch and extract sequences and labels\n",
    "    sample = g[index]\n",
    "    sequences = sample[0]\n",
    "    labels = sample[1]\n",
    "\n",
    "    # Set up window for displaying images\n",
    "    cv2.namedWindow(\"Video\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # Iterate over sequences and display images\n",
    "    for i, image_seq in enumerate(sequences):\n",
    "        for j, image in enumerate(image_seq):\n",
    "            cv2.putText(image, f\"{options[int(yhat[index])]}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            cv2.imshow('Video', image_rgb)\n",
    "            key = cv2.waitKey(150)\n",
    "            if key == 27:  # If ESC key is pressed, break out of loop\n",
    "                break\n",
    "\n",
    "    # Destroy window after all images have been displayed\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"movinet_classifier_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image (InputLayer)          [(None, None, None, None  0         \n",
      "                             , 3)]                               \n",
      "                                                                 \n",
      " movinet (Movinet)           ({'stem': (None, None, N  4823882   \n",
      "                             one, None, 16),                     \n",
      "                              'block0_layer0': (None,            \n",
      "                              None, None, None, 16),             \n",
      "                              'block0_layer1': (None,            \n",
      "                              None, None, None, 16),             \n",
      "                              'block0_layer2': (None,            \n",
      "                              None, None, None, 16),             \n",
      "                              'block1_layer0': (None,            \n",
      "                              None, None, None, 40),             \n",
      "                              'block1_layer1': (None,            \n",
      "                              None, None, None, 40),             \n",
      "                              'block1_layer2': (None,            \n",
      "                              None, None, None, 40),             \n",
      "                              'block1_layer3': (None,            \n",
      "                              None, None, None, 40),             \n",
      "                              'block1_layer4': (None,            \n",
      "                              None, None, None, 40),             \n",
      "                              'block2_layer0': (None,            \n",
      "                              None, None, None, 72),             \n",
      "                              'block2_layer1': (None,            \n",
      "                              None, None, None, 72),             \n",
      "                              'block2_layer2': (None,            \n",
      "                              None, None, None, 72),             \n",
      "                              'block2_layer3': (None,            \n",
      "                              None, None, None, 72),             \n",
      "                              'block2_layer4': (None,            \n",
      "                              None, None, None, 72),             \n",
      "                              'block3_layer0': (None,            \n",
      "                              None, None, None, 72),             \n",
      "                              'block3_layer1': (None,            \n",
      "                              None, None, None, 72),             \n",
      "                              'block3_layer2': (None,            \n",
      "                              None, None, None, 72),             \n",
      "                              'block3_layer3': (None,            \n",
      "                              None, None, None, 72),             \n",
      "                              'block3_layer4': (None,            \n",
      "                              None, None, None, 72),             \n",
      "                              'block3_layer5': (None,            \n",
      "                              None, None, None, 72),             \n",
      "                              'block4_layer0': (None,            \n",
      "                              None, None, None, 144),            \n",
      "                              'block4_layer1': (None,            \n",
      "                              None, None, None, 144),            \n",
      "                              'block4_layer2': (None,            \n",
      "                              None, None, None, 144),            \n",
      "                              'block4_layer3': (None,            \n",
      "                              None, None, None, 144),            \n",
      "                              'block4_layer4': (None,            \n",
      "                              None, None, None, 144),            \n",
      "                              'block4_layer5': (None,            \n",
      "                              None, None, None, 144),            \n",
      "                              'block4_layer6': (None,            \n",
      "                              None, None, None, 144),            \n",
      "                              'head': (None, None, No            \n",
      "                             ne, None, 640)},                    \n",
      "                              {'state_block0_layer0_p            \n",
      "                             ool_buffer': (None, None            \n",
      "                             , 1, 1, 40),                        \n",
      "                              'state_block0_layer0_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block0_layer1_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 40),                         \n",
      "                              'state_block0_layer1_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block0_layer2_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 64),                         \n",
      "                              'state_block0_layer2_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block1_layer0_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 96),                         \n",
      "                              'state_block1_layer0_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block1_layer1_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 120),                        \n",
      "                              'state_block1_layer1_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block1_layer2_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 96),                         \n",
      "                              'state_block1_layer2_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block1_layer3_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 96),                         \n",
      "                              'state_block1_layer3_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block1_layer4_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 120),                        \n",
      "                              'state_block1_layer4_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block2_layer0_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 240),                        \n",
      "                              'state_block2_layer0_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block2_layer1_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 160),                        \n",
      "                              'state_block2_layer1_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block2_layer2_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 240),                        \n",
      "                              'state_block2_layer2_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block2_layer3_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 192),                        \n",
      "                              'state_block2_layer3_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block2_layer4_po            \n",
      "                             ol_buffer': (None, None,            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              1, 1, 240),                        \n",
      "                              'state_block2_layer4_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block3_layer0_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 240),                        \n",
      "                              'state_block3_layer0_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block3_layer1_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 240),                        \n",
      "                              'state_block3_layer1_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block3_layer2_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 240),                        \n",
      "                              'state_block3_layer2_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block3_layer3_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 240),                        \n",
      "                              'state_block3_layer3_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block3_layer4_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 144),                        \n",
      "                              'state_block3_layer4_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block3_layer5_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 240),                        \n",
      "                              'state_block3_layer5_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block4_layer0_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 480),                        \n",
      "                              'state_block4_layer0_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block4_layer1_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 384),                        \n",
      "                              'state_block4_layer1_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block4_layer2_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 384),                        \n",
      "                              'state_block4_layer2_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block4_layer3_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 480),                        \n",
      "                              'state_block4_layer3_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block4_layer4_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 480),                        \n",
      "                              'state_block4_layer4_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block4_layer5_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 480),                        \n",
      "                              'state_block4_layer5_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_block4_layer6_po            \n",
      "                             ol_buffer': (None, None,            \n",
      "                              1, 1, 576),                        \n",
      "                              'state_block4_layer6_po            \n",
      "                             ol_frame_count': (1,),              \n",
      "                              'state_head_pool_buffer            \n",
      "                             ': (None, None, None, No            \n",
      "                             ne, 640),                           \n",
      "                              'state_head_pool_frame_            \n",
      "                             count': (1,)})                      \n",
      "                                                                 \n",
      " classifier_head_1 (Classifi  (None, 8)                1329160   \n",
      " erHead)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,153,042\n",
      "Trainable params: 6,113,954\n",
      "Non-trainable params: 39,088\n",
      "_________________________________________________________________\n",
      "None\n",
      "601/601 [==============================] - 297s 466ms/step\n"
     ]
    }
   ],
   "source": [
    "pred, real_test_gen =setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample(real_test_gen, pred, index=250) #put any index value between 0 and 601(not included). Please note that the model gets confused between safe driving, drowsiness and calling right due to lack of front view.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
