{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import random\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from official.projects.movinet.modeling import movinet\n",
    "from official.projects.movinet.modeling import movinet_model\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T08:41:36.505229Z",
     "iopub.status.busy": "2023-03-22T08:41:36.504869Z",
     "iopub.status.idle": "2023-03-22T08:41:45.474557Z",
     "shell.execute_reply": "2023-03-22T08:41:45.465860Z",
     "shell.execute_reply.started": "2023-03-22T08:41:36.505194Z"
    },
    "id": "yTLZzkd-lFTF"
   },
   "outputs": [],
   "source": [
    "def setup():\n",
    "    model_id = 'a2'\n",
    "    resolution = 224\n",
    "    batch_size=8\n",
    "    num_frames=10\n",
    "    tf.keras.backend.clear_session()\n",
    "    use_positional_encoding = model_id in {'a3','a4','a5'}\n",
    "\n",
    "    backbone = movinet.Movinet(model_id=model_id, conv_type ='2plus1d', se_type='2plus3d', activation='hard_swish', gating_activation='hard_sigmoid', use_positional_encoding=use_positional_encoding )\n",
    "    backbone.trainable = True\n",
    "\n",
    "    model = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600)\n",
    "    model.build([None, None, None, None, 3])\n",
    "\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "            filepath='/content/drive/MyDrive/cp.ckpt3',\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "\n",
    "        )\n",
    "\n",
    "    def build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n",
    "        model = movinet_model.MovinetClassifier(\n",
    "        backbone=backbone,\n",
    "        num_classes=num_classes)\n",
    "        model.build([batch_size, num_frames, resolution, resolution, 3])\n",
    "\n",
    "        return model\n",
    "\n",
    "    model = build_classifier(batch_size, num_frames, resolution, backbone, 8)\n",
    "\n",
    "    num_epochs = 1\n",
    "\n",
    "    loss_obj = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    optimizer = tfa.optimizers.AdaBelief(learning_rate = 0.0007, weight_decay= 0.0001)\n",
    "    model.compile(loss=loss_obj, optimizer=optimizer, metrics=['accuracy'])\n",
    "    checkpoint = tf.train.Checkpoint(model)\n",
    "    checkpoint.restore(r'C:\\Users\\Asus\\Desktop\\Fds project\\Driver_Distraction\\driver_distraction_demo\\cp.ckpt1 (1)')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DlMO_x4Dabtj",
    "outputId": "a19c9f84-294e-4e9b-aafc-476163764fc3"
   },
   "outputs": [],
   "source": [
    "def play_demo(model,vid):\n",
    "\n",
    "    options=['Safe Driving','Hair and Makeup', 'Infotainment System','Texting Left','Texting Right','Call left','Call Right','Drowsy']\n",
    "\n",
    "    path=r\"C:\\Users\\Asus\\Desktop\\Fds project\\Driver_Distraction\\driver_distraction_demo\\demonew\"\n",
    "    path=os.path.join(path,vid)\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "\n",
    "    video_frames = np.zeros((1, 10, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "\n",
    "    j=1\n",
    "    while(j):\n",
    "        for i in range(10):\n",
    "            ret, frame = cap.read()\n",
    "            if ret==False:\n",
    "                j=0\n",
    "                break\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "            frame = frame.astype(np.float32)/255.0\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            rgb_frame[:, :, [0, 2]] = rgb_frame[:, :, [2, 0]]\n",
    "            video_frames[0, i, :, :, :] = rgb_frame\n",
    "        if (j==1):\n",
    "            preds=model.predict(video_frames)\n",
    "            prediction_p = tf.nn.softmax(preds)\n",
    "        yhat = np.argmax(prediction_p,axis=1)\n",
    "        if (j==1):\n",
    "            for i in range(10):\n",
    "                frame = video_frames[0, i, :, :, :]\n",
    "                cv2.putText(frame, f\"{options[int(yhat)]}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                cv2.imshow('frame',frame)\n",
    "                cv2.waitKey(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 18s 18s/step\n",
      "1/1 [==============================] - 1s 511ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(r\"C:\\Users\\Asus\\Desktop\\Fds project\\Driver_Distraction\\driver_distraction_demo\\demonew\"):\n",
    "    play_demo(model,i)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
